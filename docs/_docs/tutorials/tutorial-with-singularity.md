---
title: Tutorial with Singularity
---

# Data processing with Singularity

This tutorial takes you through the steps of running the MIMA pipeline for data processing of shotgun metagenomics sequenced reads using the assembly-free approach. 

This tutorial depends on the following:

- **Compute environment**
  - OpenPBS system on a high-performance cluster (HPC)
  - System must have `Singularity` installed

{% include alert.html type="danger" title="to-do" content="The tutorial assumes that you will be running the pipeline one a PBS (or have a queuing management system) system with `Singularity` installed via `modules`" %}

- **Reference databases**
  - Many of the data processing steps require access to reference databases that are too big to be included in the Singularity container
  - You will need to have these already installed on your system or HPC environment and tell the pipeline of the location (this will be detailed in the relevant steps)

- **Study data assumptions**
  - Paired-end sequencing with two files \_R1 and \_R2 files
  - By default the pipeline assumes human-host metagenomics studies and decontamination is done against the human genome, you can provide alternative references (see the tutorial or command usage documentation)

# The pipeline

The pipeline consists of the following components which are shown in the schema and briefly described below.

![]({{site.baseurl}}/assets/img/tutorials/no-singularity/tut_OverallSchema.png)

## Data processing

1. Quality control (QC) of the sequenced reads
2. Taxonomy profiling after QC (this step can be run in parallel with step 3)
3. Functional profiling after QC (this step can be run in parallel with step 2)

In steps 1 to 3, the pipeline generates PBS scripts (currently only supports OpenPBS) which then have to be submitted to the PBS manager to actually process the sequenced reads and generate the output.

## Analysis and visualisation

Comes after the data has been processed and is covered in a separate tutorial.

---

# Getting started

To work with this tutorial, you need to first

1. [Install MIMA Pipeline Singularity container]({{site.baseurl}}/docs/installation)
2. [Download tutorial data](download-tutorial-data)

## Working directory

For this tutorial we will assume that the `mima_tutorial` is the working directory located in your *home directory* (`~`). Hence, we will try to always make sure we are in the right directory first before executing a command, for example, run the commands

```
$ cd ~/mima_tutorial
$ tree .
```

- the starting directory structure for `mima_tutorial` should look like:

```
mima_tutorial
├── manifest.csv
├── metadata.tsv
├── pbs_header_func.cfg
├── pbs_header_qc.cfg
├── pbs_header_taxa.cfg
└── raw_data/
    ├── Sample_A_1.fastq.gz
    ├── Sample_A_2.fastq.gz
    ├── Sample_B_1.fastq.gz
    ├── Sample_B_2.fastq.gz
    └── ...
```

From here on, `~/mima_tutorial` will refer to the root directory as depicted above. Replace this path if you saved the tutorial data in another location.


## How this tutorial works

The tutorial have five sub-sections for each of the three steps mentioned above:

Step:
    
a) Brief introduction

b) Command to generate PBS scripts 

c) Command to submit PBS scripts as jobs

d) Expected outputs after PBS job completes

e) Post-processing step (some are optional)

----

# Step 1: QC module

## 1a) QC: introduction

Quality control checks to make sure that the sequenced reads obtained from the sequencing machine is of good quality. Bad quality reads or artefacts due to sequencing error if not removed can lead to spurious results and affect downstream analyses. There are a number of tools available for checking read quality of high-throughput read sequences.

This step must be done before Taxonomy and Function profiling.

This pipeline uses the following tools:

* [BBTool suite](https://jgi.doe.gov/data-and-tools/software-tools/bbtools/)
* [Fastp](https://github.com/OpenGene/fastp)
* [Minimap2](https://github.com/lh3/minimap2)

**Pipeline**

The bash scripts generated by this step performs the following 4 key steps. The module also generates $N$ number of PBS scripts (default=4 using the `--num-pbs-jobs` parameter setting), which calls the bash scripts sequentially.

> In this tutorial, we have 9 samples which we will spread across 3 PBS jobs. The output will consists of 9 bash scripts and 3 PBS scripts, where one PBS will execute quality checking for three samples.

Key steps in the quality control module are shown in the figure below and described as follows:

![QC PBS pipeline]({{site.baseurl}}/assets/img/tutorials/no-singularity/tut_QCpipeline.png)

1. **repair** \- uses repair\.sh from BBTools/BBMap tool suite \- repairs the sequenced reads and outputs any singleton reads \(these are orphaned reads that are missing either the forward or reverse partner read\)
2. **dereplicate** \- uses clumpify\.sh from BBTools/BBMap tool suite and removes duplicate reads\. It also clusters reads for faster downstream processing
3. **quality check** \- uses fastp\.sh and checks the quality of the reads and removes any reads that are of low quality\, too long or too short
4. **decontamination** \- uses minimap2\.sh\, which maps sequenced reads against a user\-specified reference genome \(fasta\) file \(e\.g\.\, human\) and removes these host\-reads from the data\. The **cleaned** sequence output then becomes the input for the next steps: taxonomy or function profiling.

There is an optional step in the diagram (QC\_report) that generates a summary report *after all* PBS scripts have been run for all samples in the study.

## 1b) QC: Generate PBS scripts

- The following command is all one line without the backslashes (`\`)
    - the backslash (`\`) at the end of each line informs the terminal that the command has not finished and there's more to come
    - we break up the command for readability purposes to explain each parameter

```
$ singularity run --app mima-qc $SANDBOX -i ~/mima_tutorial/raw_data \
-o ~/mima_tutorial/output \
-m ~/mima_tutorial/manifest.csv \
-e your.email@addr.com \
--mode singularity \
--pbs-config pbs_header_qc.cfg
```

**Parameters explained**

| Parameters | Required? | Description |
| ---------- | ---------| ----------- |
| `-i <input>` | yes | must be *full path* to where the raw sequenced reads are stored (these files often have the \*.fastq.gz or \*.fq.gz extension). This path is used to find the *FileID\_R1* and *FileID\_R2* columns specified in the *manifest.csv* file provided (see below). |
| `-o <output>` | yes | must be the *full path* to where you would like the output files to be saved. The `<output>` path will be created if it does not exists. **Note** if there are already existing subdirectories in the `<output>` path, then this step will fail. |
| `-m <manifest.csv>` | yes | a comma-seperated file (\*.csv) that has three columns with the headers: **Sample\_ID, FileID\_R1, FileID\_R2** see the example below. *Note* the fileID\_R1 and fileID\_R2 are relative to the `-i <input>` path provided. |
| `-e <email>` | yes | email address for the PBS script so that you are notified when your PBS jobs complete (note that the current configuration generates one PBS script per sample file, so you will get an alert per job. So, if you have 100 samples in your study, you will have 100 emails) |
| `--mode simgularity` | no (default='single') | set this if you are running in the singularity mode. By default, the PBS scripts generated are for the 'standalone' option, that is without Singularity |
| `--pbs-config` | yes if `--mode singularity` | path to the pbs configuration file (see below). You must specify this parameter if `--mode singularity` is set. You do not need to set this parameter if running outside of Singularity | 


*Manifest.csv* file example

```
Sample_ID,FileID_R1,FileID_R2
SRR17380209,SRR17380209.sra_1.fastq.gz,SRR17380209.sra_2.fastq.gz
SRR17380232,SRR17380232.sra_1.fastq.gz,SRR17380232.sra_2.fastq.gz
SRR17380236,SRR17380236.sra_1.fastq.gz,SRR17380236.sra_2.fastq.gz
SRR17380231,SRR17380231.sra_1.fastq.gz,SRR17380231.sra_2.fastq.gz
SRR17380218,SRR17380218.sra_1.fastq.gz,SRR17380218.sra_2.fastq.gz
...
```

*pbs_header_qc.cfg* is the PBS settings and Singularity settings that will be copied to the top of all PBS script files. Below is the PBS configuration file we have provided for you.
```
#!/bin/bash
#PBS -N QC_module_0
#PBS -l ncpus=8
#PBS -l walltime=2:00:00
#PBS -l mem=64GB
#PBS -m ae
#PBS -j oe

set -x
module load singularity/3.6.4

IMAGE_DIR=/home/z3534482/scratch/29_MRC_Pipelines/29.02_MRC_SS/mima-singularity-XYC/mima-pipeline
export SINGULARITY_BIND="/srv/scratch/z3534482:/srv/scratch/z3534482,/srv/scratch/mrcbio:/srv/scratch/mrcbio,/srv/scratch/mrcgut:/srv/scratch/mrcgut"
```



**Expected output**

* After this command you should get a new `output` directory within `<PROJECT_PATH>`
* Within `output/`, there will be a sub-drectory `QC_module`
    * Inside `output/QC_module` should be one PBS script (files with \*.pbs extension) for each of the samples specified in the `manifest.csv` file
    * We need these PBS scripts for the next step

```
$ tree ~/mima_tutorial
```

- only the `output` folder are shown

```
mima_tutorial
└── output/
    └──  QC_module
      ├── CleanReads
      ├── qcModule_0.pbs
      ├── qcModule_1.pbs
      ├── qcModule_2.pbs
      ├── QCReport
      ├── SRR17380115.sh
      ├── SRR17380118.sh
      ├── SRR17380122.sh
      ├── SRR17380209.sh
      ├── SRR17380218.sh
      ├── SRR17380222.sh
      ├── SRR17380231.sh
      ├── SRR17380232.sh
      └── SRR17380236.sh
```

## 1c) QC: Submit PBS jobs

- Examine one of the PBS scripts to be submitted

```
$ cat ~/mima_tutorial/output/QC_module/qcModule_0.pbs
```

- The first 13 lines are the same as `pbs_header_qc.cfg` configuration file as it has been directly inserted (see above for explanation)

```
#!/bin/bash
#PBS -N QC_module_0
#PBS -l ncpus=8
#PBS -l walltime=2:00:00
#PBS -l mem=64GB
#PBS -m ae
#PBS -j oe

set -x
module load singularity/3.6.4

IMAGE_DIR=/home/z3534482/scratch/29_MRC_Pipelines/29.02_MRC_SS/mima-singularity-XYC/mima-pipeline
export SINGULARITY_BIND="/srv/scratch/z3534482:/srv/scratch/z3534482,/srv/scratch/mrcbio:/srv/scratch/mrcbio,/srv/scratch/mrcgut:/srv/scratch/mrcgut"


cd /home/z3534482/examples/mini_mock_v2/output03/QC_module/

singularity exec ${IMAGE_DIR} bash /home/z3534482/examples/mini_mock_v2/output03/QC_module/SRR17380209.sh > SRR17380209_qc_module.log 2>&1
singularity exec ${IMAGE_DIR} bash /home/z3534482/examples/mini_mock_v2/output03/QC_module/SRR17380232.sh > SRR17380232_qc_module.log 2>&1
singularity exec ${IMAGE_DIR} bash /home/z3534482/examples/mini_mock_v2/output03/QC_module/SRR17380236.sh > SRR17380236_qc_module.log 2>&1
```

- Navigate to the `mima_tutorial/output/QC_module` (replace `<mima_tutorial>` with where you created the folder)
- List the files in this directory, you should see one `*.pbs` file for each of your samples that was listed in the *manifest.csv* file
- Submit the job by typing the `qsub` command
- You can check the job has been submitted with `qstat`

```
$ cd ~/mima_tutorial/output/QC_module
$ qsub qcModule_0.pbs
```

- repeat the `qsub` command for each of the `qcModule_1.pbs` and `qcModule_2.pbs` files
- wait until all PBS jobs have completed

{% include alert.html type="tip" title="tip" content="We navigate to the directory that contains the PBS files because the PBS log files will be saved in the directory from where the job is submitted. Some will allow the PBS directory `#PBS -j /path/to/log/file/` but at the time of writing this tutorial, this directive was not working properly for us. You can modify these settings in the `pbs_header_qc.cfg` to suit your system needs." %}


## 1d) QC: outputs

- After the PBS job completes then you should have the following outputs

```
$ tree ~/mima_tutorial/output/QC_module
```

- The output directory sturcture will resemble the tree below
- We only show outputs for sample `SRR17380209` with `...` meaning *and others*
- You'll have a set of output for each sample listed in the `manifest.csv` file

```
.
├── CleanReads
│   ├── SRR17380209_clean_1.fq.gz
│   ├── SRR17380209_clean_2.fq.gz
│   └── ...
├── QC_module_0.o3492023
├── qcModule_0.pbs
├── qcModule_1.pbs
├── qcModule_2.pbs
├── QCReport
│   ├── SRR17380209.json
│   ├── SRR17380209.outreport.html
│   └── ...
├── ...
├── SRR17380209_qc_module.log
├── SRR17380209.sh
├── SRR17380209_singletons.fq.gz
└── ...
```

## 1e) [optional] QC report

{% include alert.html type="warning" title="Note" content="This step occurs after all the PBS jobs for QC have completed" %}

- You can also generate a summary QC Report after *all samples* have been quality checked
- This step can be run directly from command line and does not generate a PBS script

> Beware that if you have failed PBS log files (\*.o) in your input directory, the qc\_report.py module will not give a nice error and may fail. It reads in all PBS log files in the input directory including those that failed.

- In the terminal, type the following command:

```
$ singularity run --app mima-qc-report $SANDBOX -i ~/mima_tutorial/output/QC_module \
-o ~/mima_tutorial/output \
--manifest ~/mima_tutorial/manifest.csv
```

- Output is a comma separated table file located in `~/mima_tutorial/output/QC_module/QC_report.csv`

```
$ cat ~/mima_tutorial/output/QC_module/QC_report.csv
```

```
```


----

# Step 2: Taxonomy profiling

## 2a) Taxa: introduction

Taxonomy profiling takes the cleaned sequence reads as input and matches them against a reference database of previously characterised sequences for taxonomy classification. There are many different classification tools, for example: Kraken2, Metaphlan, Clark, Centrifuge, MEGAN, and many more.

This pipeline uses Kraken2, which comes with its own reference database but you can also generate your own. In this pipeline, we will use the [GTDB](https://gtdb.ecogenomic.org/) database (release 95) and have built a Kraken2 database.

**Pipeline**

One bash script per sample is generated and since Kraken requires big memory, there will only be one PBS script that will execute each sample sequentially.

> In this tutorial, we have 9 samples which will be executed within one PBS job. The output will consists of 9 bash scripts and one PBS script.

Key steps in the taxonomy profiling module are shown in the figure below and described as follows:

![Taxonomy PBS script mini-pipeline using Kraken2 classifier]({{site.baseurl}}/assets/img/tutorials/no-singularity/tut_TAXApipeline.png)

1. Kraken2 classifies the reads to taxa
2. Bracken takes the Kraken2 output to estimate abundances for a given taxonomic rank
3. The final step (**generate table**) is performed after *all samples* have been processed. This combines the output and generates a *feature table* for a given taxonomic rank. The feature table contains the count or relative abundances of taxon X occurring in sample Y.


## 2b) Taxa: Generate PBS script

- The following command is all one line without the backslashes (`\`)
    - the backslash (`\`) at the end of each line informs the terminal that the command has not finished and there's more to come
    - we break up the command for readability purposes to explain each parameter

```
$ singularity run --app mima-taxa -i ~/mima_tutorial/output/QC_module/CleanReads \
-o ~/mima_tutorial/output \
--reference-path ~/scratch/REF/GTDB/release_95/GTDB_Kraken2 \
--fwd-suffix _clean_1.fq.gz \
--rev-suffix _clean_2.fq.gz \
--read-length 150 \
--threshold 100 \
-e your.email@address.com \
--mode singularity \
--pbs-config pbs_header_taxa.cfg
```

**Required parameters**

| Parameters | Required? | Description |
| ---------- | ----------|----------- |
| `-i <input>` | yes | full path to the `<PROJECT_PATH>/output/QC_module/CleanReads` directory that was generated from Step 1) QC, above. This directory should hold all the `*_clean.fastq` files |
| `-o <output>` | yes | full path to the `<PROJECT_PATH>/output` output directory where you would like the output files to be saved, can be the same as Step 1) QC |
| `--reference-path` | yes | full path to the reference database (this pipeline uses the GTDB release 95 reference database) |
| `--fwd-suffix` | no (default=) | file suffix for cleaned forward reads from QC module |
| `--rev-suffix` | no (default=) | file suffix for cleaned reverse reads from QC module |
| `--read-length` | no (default=150) | read length for Bracken estimation, choose the value closest to your sequenced read length (choose from 50, 75, 100 and 150) |
| `--threshold` | no (default=) | Bracken filtering threshold, features with counts below this value are filtered in the abundance estimation |
| `--mode simgularity` | no (default='single') | set this if you are running in the singularity mode. By default, the PBS scripts generated are for the 'standalone' option, that is without Singularity |
| `--pbs-config` | yes if `--mode singularity` | path to the pbs configuration file (see below). You must specify this parameter if `--mode singularity` is set. You do not need to set this parameter if running outside of Singularity | 
| `-e <email>` | yes | address for the PBS script so that you are notified when your PBS jobs complete (note that the current configuration generates one PBS script per sample file, so you will get an alert per job. So, if you have 100 samples in your study, you will have 100 emails) |

**Expected output**

- After this step you should get the following PBS scripts (again, one for each sample) in the output directory `~/mima_tutorial/output/Taxonomy_profiling`
- have a look at the directory structure using `tree`

```
$ tree ~/mima_tutorial/output/Taxonomy_profiling
```

```
.
├── bracken
├── featureTables
│   └── generate_bracken_feature_table.py
├── kraken2
├── run_taxa_profiling.pbs
├── SRR17380209.sh
├── SRR17380232.sh
└── SRR17380236.sh
```

- **braken/** and **kraken2/** are subdirectories created by this step and will store the output files from the processes called in the PBS script


## 2c) Taxa: Submit PBS job

- First we'll examine the PBS script to be submitted

```
$ cat ~/mima_tutorial/output/Taxonomy_profiling/run_taxa_profiling.pbs
```

- only the top lines are shown with `...` at the end meaning more
- the first N lines are directly copied from the `pbs_header.cfg` file
- you must specify the

```
#!/bin/bash
#PBS -N QC_module_0
#PBS -l ncpus=28
#PBS -l walltime=10:00:00
#PBS -l mem=300GB
#PBS -m ae
#PBS -j oe

set -x
module load singularity/3.6.4

IMAGE_DIR=/home/z3534482/scratch/29_MRC_Pipelines/29.02_MRC_SS/mima-singularity-XYC/mima-pipeline
export SINGULARITY_BIND="/srv/scratch/z3534482:/srv/scratch/z3534482,/srv/scratch/mrcbio:/srv/scratch/mrcbio,/srv/scratch/mrcgut:/srv/scratch/mrcgut"


cd /home/z3534482/examples/mini_mock_v2/output03/Taxonomy_profiling/

singularity exec ${IMAGE_DIR} bash /home/z3534482/examples/mini_mock_v2/output03/Taxonomy_profiling/SRR17380209.sh
singularity exec ${IMAGE_DIR} bash /home/z3534482/examples/mini_mock_v2/output03/Taxonomy_profiling/SRR17380232.sh
...
```

- change directory to `~/mima_tutorial/output/Taxonomy_profiling`
- Submit PBS script with `qsub`

```
$ cd ~/mima_tutorial/output/Taxonomy_profiling
$ qsub run_taxa_profiling.pbs
```

- You can check the job has been submitted with `qstat`
- Wait for the job to complete


## 2d) Taxa: outputs

- After the PBS job completes then you should have the following outputs

```
$ tree ~/mima_tutorial/output/Taxonomy_profiling
```

- only a subset of the outputs are shown below with `...` meaning *and others*
- you'll have a set of output for each sample listed in the `manifest.csv` file

```
.
├── bracken
│   ├── SRR17380218_class
│   ├── SRR17380218_family
│   ├── SRR17380218_genus
│   ├── SRR17380218.kraken2_bracken_classes.report
│   ├── SRR17380218.kraken2_bracken_families.report
│   ├── SRR17380218.kraken2_bracken_genuses.report
│   ├── SRR17380218.kraken2_bracken_orders.report
│   ├── SRR17380218.kraken2_bracken_phylums.report
│   ├── SRR17380218.kraken2_bracken_species.report
│   ├── SRR17380218_order
│   ├── SRR17380218_phylum
│   ├── SRR17380218_species
│   └── ...
├── featureTables
│   └── generate_bracken_feature_table.py
├── kraken2
│   ├── SRR17380218.kraken2.output
│   ├── SRR17380218.kraken2.report
│   ├── ...
│   ├── SRR17380231.kraken2.output
│   └── SRR17380231.kraken2.report
├── QC_module_0.o3492470
├── run_taxa_profiling.pbs
├── SRR17380209.sh
├── SRR17380218_bracken.log
├── SRR17380218.sh
├── SRR17380222_bracken.log
├── SRR17380222.sh
├── SRR17380231_bracken.log
├── SRR17380231.sh
├── SRR17380232.sh
└── SRR17380236.sh
```

**Output files**

| Directory / Files | Description |
| ----------------- | ----------- |
| output | specified in the `--output-dir <output>` parameter set in step 1b) |
| Taxonomy\_profiling | contains all files and output from this step |
| Taxonomy\_profiling/\*.sh | are all the bash scripts generated by step 2b) for taxonomy profiling |
| Taxonomy\_profiling/run\_taxa\_profiling.pbs | is the PBS wrapper generated by step 2b) that will execute each sample sequentially |
| Taxonomy\_profiling/bracken | consists of the abundance estimation files from Bracken, one per sample, output after PBS submission |
| Taxonomy\_profiling/featureTables | consists of the merged abundance tables generated by step 2e) below |
| Taxonomy\_profiling/kraken2 | consists of the output from Kraken2 (two files per sample), output after PBS submission |

**Profiler output**

* For details of Kraken2 output files, see their [documentation](https://github.com/DerrickWood/kraken2/wiki/Manual#output-formats)
* For details of Bracken output files, see their [documentation](https://ccb.jhu.edu/software/bracken/index.shtml?t=manual#format)

## 2e) Taxa: Generate taxonomy abundance table

```
$ cd ~/mima_tutorial/output/Taxonomy_profiling/featureTables
$ singularity exec $SANDBOX python3 generate_bracken_feature_table.py
$ tree .
```

- All bracken output files from Step 3b will be concatenated into a table, one for each taxonomic rank from Phylum to Species
    - table rows are taxonomy features
    - table columns are abundances
- by default, the tables contain both discrete counts and relative abundances
- the `generate_bracken_feature_table.py` will split the default output into two files with the suffices:
    - `_counts` for discrete counts and
    - `_relAbund` for relative abundances

```
.
├── bracken_FT_class
├── bracken_FT_class_counts
├── bracken_FT_class_relAbund
├── bracken_FT_family
├── bracken_FT_family_counts
├── bracken_FT_family_relAbund
├── bracken_FT_genus
├── bracken_FT_genus_counts
├── bracken_FT_genus_relAbund
├── bracken_FT_order
├── bracken_FT_order_counts
├── bracken_FT_order_relAbund
├── bracken_FT_phylum
├── bracken_FT_phylum_counts
├── bracken_FT_phylum_relAbund
├── bracken_FT_species
├── bracken_FT_species_counts
├── bracken_FT_species_relAbund
├── combine_bracken_class.log
├── combine_bracken_family.log
├── combine_bracken_genus.log
├── combine_bracken_order.log
├── combine_bracken_phylum.log
├── combine_bracken_species.log
└── generate_bracken_feature_table.py
```


---

# Step 3: Functional profiling

## 3a) Function: introduction

Functional profiling, like taxonomy profiling, takes the cleaned sequenced reads as input and matches them against a reference database of previously charactered sequences to annotate as genes. There are different types of functional classification tools available.

This pipeline uses [HUMAnN3](https://huttenhower.sph.harvard.edu/humann/), which comes with its own reference databases. You will need to download these on to the HPC system you are working with if it's not already done so. If it's already downloaded, then you will need to know the paths to the reference databases for this step.

**ADD REFERENCE DATABASE INFO**

**Pipeline**

One PBS script per sample will be generated in this step. The key steps are shown in the figure below and described as follows:

![Function mini-pipeline]({{site.baseurl}}/assets/img/tutorials/no-singularity/tut_function_pipeline.png)

1. HUMAnN3 is used for processing and generates three outputs for each sample: (i) gene families, (ii) pathway abundances and (iii) pathway coverage
2. The final step (**generate table**) is performed after *all samples* have been processed. This combines the output and generates a *feature table*. The feature table contains the abundance of gene/pathway X in sample Y.


## 3b) Function: Generate PBS scripts

- The following command is all one line without the backslashes (`\`)
    - the backslash (`\`) at the end of each line informs the terminal that the command has not finished and there's more to come
    - we break up the command for readability purposes to explain each parameter

```
$ singularity run --app mima-func $SANDBOX -i ~/mima_tutorial/output/QC_module/CleanReads \
-o ~/mima_tutorial/output \
--fwd-suffix _clean_1.fq.gz \
--rev-suffix _clean_2.fq.gz \
--nucleotide-database /srv/scratch/mrcbio/db/humann3/chocophlan \
--protein-database /srv/scratch/mrcbio/db/humann3/uniref \
--metaphlan-database="--bowtie2db /srv/scratch/mrcbio/db/metaphlan_databases" \
-e <your.email@address.com> \
--mode singularity \
--pbs-config pbs_header_taxa.cfg
```

**Required parameters**

| Parameters | Required? | Description |
| ---------- | --------- | ----------- |
| `-i <input>` | yes | full path to the `<PROJECT_PATH>/output/QC_module/CleanReads` directory that was generated from Step 1) QC, above. This directory should hold all the `*_clean.fastq` files |
| `-o <output>` | yes | full path to the `<PROJECT_PATH>/output` output directory where you would like the output files to be saved, can be the same as Step 1) QC |
| `--fwd-suffix` | no (default=) | file suffix for cleaned forward reads from QC module |
| `--fwd-suffix` | no (default=) | file suffix for cleaned reverse reads from QC module |
| `--nucleotide-database <path>` | yes | directory containing the nucleotide database, DEFAULT: /refdb/humann/chocophlan |
| `--protein-database <path>` | yes | directory containing the protein database, DEFAULT: /refdb/humann/uniref |
| `--metaphlan-database <path>` | yes | directory containing the metaphlan database, DEFAULT: /refdb/humann/metaphlan\_databases |
| `--mode simgularity` | no (default='single') | set this if you are running in the singularity mode. By default, the PBS scripts generated are for the 'standalone' option, that is without Singularity |
| `--pbs-config` | yes if `--mode singularity` | path to the pbs configuration file (see below). You must specify this parameter if `--mode singularity` is set. You do not need to set this parameter if running outside of Singularity | 
| `-e <email>` | yes | address for the PBS script so that you are notified when your PBS jobs complete (note that the current configuration generates one PBS script per sample file, so you will get an alert per job. So, if you have 100 samples in your study, you will have 100 emails) |

**Expected output**

- After this step you should get the following PBS scripts (one per sample) in the output directory `~/mima_tutorial/output/Function_profiling`

```
$ tree ~/mima_tutorial/output/Function_profiling
```

```
├── featureTables
│   └── generate_func_feature_tables.pbs
├── SRR17380209.pbs
├── SRR17380218.pbs
├── SRR17380222.pbs
├── SRR17380231.pbs
├── SRR17380232.pbs
└── SRR17380236.pbs
```

## 3c) Function: Submit PBS jobs

- Examine one of the PBS scripts

```
$ cat ~/mima_tutorial/output/Function_profiling/SRR17380209.pbs
```

- Your PBS script might look a little different to the one below, especially the `~` symbols will be replaced with your actual home directory, for example it might be something like `/home/<user_name>/` depending on how the system administrator has set up the HPC infrastructure
- The first few lines come from the `pbs_header_func.cfg` configuration file
  - `#PBS` are PBS settings
  - `IMAGE_DIR` points to the full path to sandbox
  - `SINGULARITY_BIND` sets other directory paths that need to be accessed, for example, reference databases. It is a comma separated list of `source:destiation` pairs.

```
#!/bin/bash
#PBS -N QC_module_0
#PBS -l ncpus=8
#PBS -l walltime=8:00:00
#PBS -l mem=64GB
#PBS -m ae
#PBS -j oe

set -x
module load singularity/3.6.4

IMAGE_DIR=/home/z3534482/scratch/29_MRC_Pipelines/29.02_MRC_SS/mima-singularity-XYC/mima-pipeline
export SINGULARITY_BIND="/srv/scratch/z3534482:/srv/scratch/z3534482,/srv/scratch/mrcbio:/srv/scratch/mrcbio,/srv/scratch/mrcgut:/srv/scratch/mrcgut"


cd ~/mima_tutorial/output/Function_profiling/

# Execute HUMAnN3
cat ~/mima_tutorial/output/QC_module/CleanReads/SRR17380209_clean_1.fq.gz ~/mima_tutorial/output/QC_module/CleanReads/SRR17380209_clean_2.fq.gz > ~/mima_tutorial/output/Function_profiling/SRR17380209_combine.fq.gz

outdir=~/mima_tutorial/output/Function_profiling/
singularity exec ${IMAGE_DIR} humann -i ${outdir}SRR17380209_combine.fq.gz --threads 28 \
-o $outdir --memory-use maximum \
--nucleotide-database /srv/scratch/mrcbio/db/humann3/chocophlan \
--protein-database /srv/scratch/mrcbio/db/humann3/uniref \
--metaphlan-options="--bowtie2db --bowtie2db /srv/scratch/mrcbio/db/metaphlan_databases" \
--search-mode uniref90
```

- Change directory to `~/mima_tutorial/output/Functional_profiling`
- Submit the PBS job using `qsub`
  - Repeat this for each `*.pbs` file

```
$ cd ~/mima_tutorial/output/Functional_profiling
$ qsub SRR17380209.pbs
```

- You can check your jobs using `qstat`
- Wait until all PBS jobs have completed

## 3d) Function: output

- After all PBS job completes then you should have the following outputs

```
$ tree ~/mima_tutorial/output/Function_profiling
```

- only a subset of the outputs are shown below with `...` meaning *and others*
- you'll have a set of output for each sample listed in the `manifest.csv` file

```

```


**Profiler output**

* For details of HUMAnN3 output files, see their [documentation](https://github.com/biobakery/humann#output-files)

## 3e) Function: Generate function feature tables

{% include alert.html type="warning" title="Note" content="This step occurs after all the PBS jobs for Function profiling have completed" %}

* After **all samples** have been functionally annotated, we need to combine the tables together and normalise the abundances
* There will be a table for
    * genefamilies
    * pathabundances
    * pathcoverages
* In the terminal, navigate to the `~/mima_tutorial/output/Fuctional_profiling/featureTables`
* Submit the PBS script named `generate_func_feature_tables.pbs`

```
$ cd <PROJECT_PATH>/output/Functional_profiling/featureTables
$ qsub generate_func_feature_tables.pbs
```

**Output**

* Once the job completes you will have 7 output files, those starting with `merge_humann3table_` prefixes

```
~/mima_tutorial/
└── output/
    ├── Function_profiling
    │   ├── featureTables
    │   ├── func_table.o2807928
    │   ├── generate_func_feature_tables.pbs
    │   ├── merge_humann3table_genefamilies.cmp_uniref90_KO.txt
    │   ├── merge_humann3table_genefamilies.cpm.txt
    │   ├── merge_humann3table_genefamilies.txt
    │   ├── merge_humann3table_pathabundance.cmp.txt
    │   ├── merge_humann3table_pathabundance.txt
    │   ├── merge_humann3table_pathcoverage.cmp.txt
    │   └── merge_humann3table_pathcoverage.txt
    ├── ...
```

----

# Congratulations !

You have completed processing your metagenomics data and are now ready for further analyses

Analyses usually take in the feature-tables that were created in Step 2e) Taxonomy feature tables and Step 3e) Function feature tables.
